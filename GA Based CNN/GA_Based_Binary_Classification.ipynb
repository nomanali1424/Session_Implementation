{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'C:\\Users\\Noman\\Desktop\\Session\\GA Based CNN\\Data\\animal'\n",
    "working_dir = r'C:\\Users\\Noman\\Desktop\\Session\\GA Based CNN\\Data\\working'\n",
    "\n",
    "train_dir = os.path.join(working_dir, 'train')\n",
    "val_dir = os.path.join(working_dir, 'val')\n",
    "test_dir = os.path.join(working_dir, 'test')\n",
    "\n",
    "for category in ['cat', 'dog']:\n",
    "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "\n",
    "def split_data(SOURCE, TRAINING, VALIDATION, TESTING, split_size):\n",
    "    files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n",
    "    files.sort()\n",
    "    \n",
    "    train_files, temp_files = train_test_split(files, test_size=(1-split_size[0]), random_state=42)\n",
    "    val_files, test_files = train_test_split(temp_files, test_size=(split_size[2]/(split_size[1]+split_size[2])), random_state=42)\n",
    "\n",
    "    for file_name in train_files:\n",
    "        shutil.copy(os.path.join(SOURCE, file_name), os.path.join(TRAINING, file_name))\n",
    "\n",
    "    for file_name in val_files:\n",
    "        shutil.copy(os.path.join(SOURCE, file_name), os.path.join(VALIDATION, file_name))\n",
    "\n",
    "    for file_name in test_files:\n",
    "        shutil.copy(os.path.join(SOURCE, file_name), os.path.join(TESTING, file_name))\n",
    "\n",
    "split_size = (0.7, 0.15, 0.15)\n",
    "\n",
    "split_data(os.path.join(base_dir, 'cat'), os.path.join(train_dir, 'cat'), os.path.join(val_dir, 'cat'), os.path.join(test_dir, 'cat'), split_size)\n",
    "split_data(os.path.join(base_dir, 'dog'), os.path.join(train_dir, 'dog'), os.path.join(val_dir, 'dog'), os.path.join(test_dir, 'dog'), split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 698 images belonging to 2 classes.\n",
      "Found 150 images belonging to 2 classes.\n",
      "Found 152 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(512, 512),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(val_dir,\n",
    "                                                     target_size=(512, 512),\n",
    "                                                     batch_size=32,\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(test_dir,\n",
    "                                                      target_size=(512, 512),\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, Conv2D, MaxPooling2D, RepeatVector\n",
    "from sklearn.metrics import f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Classifier(f1, f2, f3, f4, k, a1, a2, a3, a4, d1, op, ep):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(f1, (k,k), activation = a1, input_shape=(512, 512, 3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(f2, (k,k), activation = a2))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(f3, (k,k), activation = a3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(f4, activation = a4))\n",
    "    model.add(Dropout(d1))\n",
    "    model.add(Dense(1 ,activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer = op, loss = keras.losses.binary_crossentropy, metric = [\"accuracy\"])\n",
    "    es = EarlyStopping(monitor = \"val_accuracy\", patience = 7)\n",
    "    model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = ep, batch_size = 100, callbacks = [es], verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from random import uniform\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Gene Parameters values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    parameters = {}\n",
    "    f1 = choice([32, 64])\n",
    "    parameters[\"f1\"] = f1\n",
    "    f2 = choice([64, 128])\n",
    "    parameters[\"f2\"] = f2\n",
    "    f3 = choice([128, 256])\n",
    "    parameters[\"f3\"] = f3\n",
    "    f4 = choice([512])\n",
    "    parameters[\"f4\"] = f4\n",
    "    k = choice([3, 5])\n",
    "    parameters[\"k\"] = k\n",
    "    a1 = choice([\"relu\"])\n",
    "    parameters[\"a1\"] = a1\n",
    "    a2 = choice([\"relu\"])\n",
    "    parameters[\"a2\"] = a2\n",
    "    a3 = choice([\"relu\"])\n",
    "    parameters[\"a3\"] = a3\n",
    "    a4 = choice([\"relu\"])\n",
    "    parameters[\"a4\"] = a4\n",
    "    d1 = round(uniform(0.2, 0.5), 1)\n",
    "    parameters[\"d1\"] = d1\n",
    "    op = choice([\"Adam\", \"rmsprop\", \"adamax\", \"nadam\", \"sgd\"])\n",
    "    parameters[\"op\"] = op\n",
    "    ep = randint(50, 100)\n",
    "    parameters[\"ep\"] = ep\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(n):\n",
    "    population = []\n",
    "    for i in range(n):\n",
    "        chromosome = initialization()\n",
    "        population.append(chromosome)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function ~ In our case we will evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_evaluation(model):\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "    return metrics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe a selection method ~ Roulette wheel selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population_fitness):\n",
    "  total = sum(population_fitness)\n",
    "  percentage = [round((x/total) * 100) for x in population_fitness]\n",
    "  selection_wheel = []\n",
    "  for pop_index,num in enumerate(percentage):\n",
    "    selection_wheel.extend([pop_index]*num)\n",
    "  parent1_ind = choice(selection_wheel)\n",
    "  parent2_ind = choice(selection_wheel)\n",
    "  return [parent1_ind, parent2_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    child1 = {}\n",
    "    child2 = {}\n",
    "\n",
    "    child1[\"f1\"] = choice([parent1[\"f1\"], parent2[\"f1\"]])\n",
    "    child1[\"f2\"] = choice([parent1[\"f2\"], parent2[\"f2\"]])\n",
    "    child1[\"f3\"] = choice([parent1[\"f3\"], parent2[\"f3\"]])\n",
    "    child1[\"f4\"] = choice([parent1[\"f4\"], parent2[\"f4\"]])\n",
    "\n",
    "    child2[\"f1\"] = choice([parent1[\"f1\"], parent2[\"f1\"]])\n",
    "    child2[\"f2\"] = choice([parent1[\"f2\"], parent2[\"f2\"]])\n",
    "    child2[\"f3\"] = choice([parent1[\"f3\"], parent2[\"f3\"]])\n",
    "    child2[\"f4\"] = choice([parent1[\"f4\"], parent2[\"f4\"]])\n",
    "    \n",
    "    child1[\"k\"] = choice([parent1[\"k\"], parent2[\"k\"]])\n",
    "    child2[\"k\"] = choice([parent1[\"k\"], parent2[\"k\"]])\n",
    "\n",
    "    child1[\"a1\"] = parent1[\"a2\"]\n",
    "    child2[\"a1\"] = parent2[\"a2\"]\n",
    "\n",
    "    child1[\"a2\"] = parent1[\"a1\"]\n",
    "    child2[\"a2\"] = parent2[\"a1\"]\n",
    "\n",
    "    child1[\"a3\"] = parent1[\"a3\"]\n",
    "    child2[\"a3\"] = parent2[\"a3\"]\n",
    "\n",
    "    child1[\"a4\"] = parent1[\"a4\"]\n",
    "    child2[\"a4\"] = parent2[\"a4\"]\n",
    "\n",
    "    child1[\"d1\"] = parent1[\"d1\"]\n",
    "    child2[\"d1\"] = parent2[\"d1\"]\n",
    "\n",
    "    child1[\"op\"] = parent1[\"op\"]\n",
    "    child2[\"op\"] = parent2[\"op\"]\n",
    "\n",
    "    child1[\"ep\"] = parent1[\"ep\"]\n",
    "    child2[\"ep\"] = parent2[\"ep\"]\n",
    "\n",
    "    return [child1, child2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(chromosome):\n",
    "    flag = randint(0,40)\n",
    "    if flag <= 20:\n",
    "        chromosome[\"ep\"] += randint(0, 10)\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramters:  {'f1': 64, 'f2': 64, 'f3': 128, 'f4': 512, 'k': 5, 'a1': 'relu', 'a2': 'relu', 'a3': 'relu', 'a4': 'relu', 'd1': 0.3, 'op': 'rmsprop', 'ep': 59}\n",
      "Invalid paramters - Build fail\n"
     ]
    }
   ],
   "source": [
    "generations = 10\n",
    "threshold = 98\n",
    "num_pop = 40\n",
    "\n",
    "population = generate_population(num_pop)\n",
    "\n",
    "for generation in range(generations):\n",
    "\n",
    "    population_fitness = []\n",
    "    for chromosome in population:\n",
    "        f1 = chromosome[\"f1\"]\n",
    "        f2 = chromosome[\"f2\"]\n",
    "        f3 = chromosome[\"f3\"]\n",
    "        f4 = chromosome[\"f4\"]\n",
    "        k = chromosome[\"k\"]\n",
    "        a1 = chromosome[\"a1\"]\n",
    "        a2 = chromosome[\"a2\"]\n",
    "        a3 = chromosome[\"a3\"]\n",
    "        a4 = chromosome[\"a4\"]\n",
    "        d1 = chromosome[\"d1\"]\n",
    "        op = chromosome[\"op\"]\n",
    "        ep = chromosome[\"ep\"]\n",
    "\n",
    "\n",
    "        try:\n",
    "            model = build_Classifier(f1, f2, f3, f4, k, a1, a2, a3, a4, d1, op, ep)\n",
    "            acc = fitness_evaluation(model)\n",
    "            print(\"Paramters: \", chromosome)\n",
    "            print(\"Accuracy: \", round(acc, 3))            \n",
    "        except:\n",
    "            acc = 0\n",
    "            print(\"Paramters: \", chromosome)\n",
    "            print(\"Invalid paramters - Build fail\")\n",
    "        population_fitness.append(acc)\n",
    "    parents_ind = selection(population_fitness)\n",
    "    parents1 = population[parents_ind[0]]\n",
    "    parents2 = population[parents_ind[1]]\n",
    "\n",
    "    children = crossover(parent1, parent2)\n",
    "    child1 = mutation(children[0])\n",
    "    child2 = mutation(children[1]) \n",
    "\n",
    "    population.append(child1)\n",
    "    population.append(child2)\n",
    "\n",
    "    print(\"Generation \", generation+1, \" Outcome: \")\n",
    "    if max(population_fitness) >= threshold:\n",
    "        print(\"Obtained desired accuracy: \", max(population_fitness))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Maximum accuracy in generation {} : {}\".format(generation+1, max(population_fitness)))\n",
    "\n",
    "    first_min = min(population_fitness)\n",
    "    first_min_ind = population_fitness.index(first_min)\n",
    "    population.remove(population[first_min_ind])\n",
    "    second_min = min(population_fitness)\n",
    "    second_min_ind = population_fitness.index(second_min)\n",
    "    population.remove(population[second_min_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
